{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_dir = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import glob\n",
    "import pydicom\n",
    "from natsort import natsorted, ns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# disable SettingWithCopyWarning\n",
    "\n",
    "\n",
    "#helper\n",
    "class dotdict(dict):\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "            \n",
    "print('import ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicom reader\n",
    "\n",
    "def normalise_to_8bit(x, lower=0.1, upper=99.9): # 1, 99 #0.05, 99.5 #0, 100\n",
    "    lower, upper = np.percentile(x, (lower, upper))\n",
    "    x = np.clip(x, lower, upper)\n",
    "    x = x - np.min(x)\n",
    "    x = x / np.max(x)\n",
    "    return (x * 255).astype(np.uint8)\n",
    "\n",
    "# discontinous volume will be splitted to continous chunks\n",
    "def load_and_split_mri_from_dicom_dir(\n",
    "    study_id,\n",
    "    series_id,\n",
    "    series_description,\n",
    "):\n",
    "    # 定义存放DICOM文件的目录路径\n",
    "    dicom_dir = f'{kaggle_dir}/train_images/{study_id}/{series_id}'\n",
    "\n",
    "    # 使用glob模块查找所有DICOM文件并进行自然排序\n",
    "    dicom_file = natsorted(glob.glob(f'{dicom_dir}/*.dcm'))\n",
    "    \n",
    "    # 从文件名中提取实例编号\n",
    "    instance_number = [int(f.split('/')[-1].split('.')[0]) for f in dicom_file]\n",
    "    # 使用pydicom读取DICOM文件\n",
    "    dicom = [pydicom.dcmread(f) for f in dicom_file]\n",
    "\n",
    "    # 初始化用于存储DICOM数据的列表\n",
    "    dicom_df = []\n",
    "\n",
    "    # 遍历实例编号和DICOM文件元数据，创建包含所需信息的字典\n",
    "    for i, d in zip(instance_number, dicom):\n",
    "        dicom_df.append(\n",
    "            dotdict(\n",
    "                study_id=study_id,\n",
    "                series_id=series_id,\n",
    "                series_description=series_description,\n",
    "                instance_number=i,\n",
    "                # 下面的字段是从DICOM元数据中提取的示例\n",
    "                # 实际使用时可能需要根据实际情况调整字段\n",
    "                ImagePositionPatient=tuple([float(v) for v in d.ImagePositionPatient]),\n",
    "                ImageOrientationPatient=tuple([float(v) for v in d.ImageOrientationPatient]),\n",
    "                PixelSpacing=tuple([float(v) for v in d.PixelSpacing]),\n",
    "                SpacingBetweenSlices=float(d.SpacingBetweenSlices),\n",
    "                SliceThickness=float(d.SliceThickness),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 将字典列表转换为pandas DataFrame\n",
    "    dicom_df = pd.DataFrame(dicom_df)\n",
    "    \n",
    "    # 按ImageOrientationPatient字段分组并筛选，确保图像方向一致性\n",
    "    dicom_df = [d for _, d in dicom_df.groupby('ImageOrientationPatient')]\n",
    "\n",
    "    # 初始化用于存储MRI数据的列表\n",
    "    mri = []\n",
    "\n",
    "    # 处理每个分组的DICOM数据\n",
    "    for df in dicom_df:\n",
    "        # 提取ImagePositionPatient和ImageOrientationPatient字段\n",
    "        position = np.array(df['ImagePositionPatient'].values.tolist())\n",
    "        orientation = np.array(df['ImageOrientationPatient'].values.tolist())\n",
    "        \n",
    "        # 计算法向量和投影位置\n",
    "        normal = np.cross(orientation[:,:3], orientation[:,3:])\n",
    "        projection = np.sum(normal * position, 1)  # 计算投影\n",
    "\n",
    "        # 将投影位置添加到DataFrame中，并按投影位置排序\n",
    "        df.loc[:, 'projection'] = projection\n",
    "        df = df.sort_values('projection')\n",
    "\n",
    "        # 确保所有切片的参数是一致的\n",
    "        assert len(df.SliceThickness.unique()) == 1\n",
    "        assert len(df.ImageOrientationPatient.unique()) == 1\n",
    "        assert len(df.SpacingBetweenSlices.unique()) == 1\n",
    "\n",
    "        # 构建三维体积数据\n",
    "        volume = [\n",
    "            dicom[instance_number.index(i)].pixel_array for i in df.instance_number\n",
    "        ]\n",
    "        volume = np.stack(volume)\n",
    "        \n",
    "        # 归一化处理\n",
    "        volume = normalise_to_8bit(volume)\n",
    "        \n",
    "        # 将处理后的DataFrame和体积数据添加到mri列表\n",
    "        mri.append(dotdict(\n",
    "            df=df,\n",
    "            volume=volume,\n",
    "        ))\n",
    "\n",
    "    # 返回处理后的MRI数据列表\n",
    "    return mri\n",
    "\n",
    "# 这段代码的主要目的是为一个包含医学影像数据的 DataFrame 添加额外的信息，\n",
    "# 包括图像的宽度（W）、高度（H）以及每个实例在三维空间中的位置（xx, yy, zz）。\n",
    "# 这是通过读取相应的 DICOM 文件并使用其元数据来实现的。\n",
    "# 计算空间坐标的公式考虑了图像的方向和像素间距，将二维图像坐标转换为三维世界坐标。\n",
    "#convert 2d x,y to 3d X,Y,Z for point in label.csv\n",
    "def add_XYZ_to_label_df(study_id_df):\n",
    "    # 为DataFrame添加新的列，用于存放图像的宽度、高度以及世界坐标xx, yy, zz\n",
    "    for col in ['W', 'H']:\n",
    "        study_id_df.loc[:, col] = 0  # 初始化宽度和高度为0\n",
    "    for col in ['xx', 'yy', 'zz']:\n",
    "        study_id_df.loc[:, col] = 0.0  # 初始化世界坐标为0.0\n",
    "\n",
    "    # 遍历DataFrame中的每一行数据\n",
    "    for t, d in study_id_df.iterrows():\n",
    "        # 构造DICOM文件的路径\n",
    "        dicom_file = f'{kaggle_dir}/train_images/{d.study_id}/{d.series_id}/{d.instance_number}.dcm'\n",
    "        # 使用pydicom读取DICOM文件\n",
    "        dicom = pydicom.dcmread(dicom_file)\n",
    "        \n",
    "        # 从DICOM元数据中获取图像的宽度和高度\n",
    "        H, W = dicom.pixel_array.shape\n",
    "        # 获取DICOM文件中的患者图像位置\n",
    "        sx, sy, sz = [float(v) for v in dicom.ImagePositionPatient]\n",
    "        # 获取DICOM文件中的图像方向\n",
    "        o0, o1, o2, o3, o4, o5 = [float(v) for v in dicom.ImageOrientationPatient]\n",
    "        # 获取DICOM文件中的像素间距\n",
    "        delx, dely = dicom.PixelSpacing\n",
    "\n",
    "        # 根据图像方向和像素间距计算世界坐标xx, yy, zz\n",
    "        xx = o0 * delx * d.x + o3 * dely * d.y + sx\n",
    "        yy = o1 * delx * d.x + o4 * dely * d.y + sy\n",
    "        zz = o2 * delx * d.x + o5 * dely * d.y + sz\n",
    "\n",
    "        # 更新DataFrame中对应的列值\n",
    "        study_id_df.loc[t, 'W'] = W\n",
    "        study_id_df.loc[t, 'H'] = H\n",
    "        study_id_df.loc[t, 'xx'] = xx\n",
    "        study_id_df.loc[t, 'yy'] = yy\n",
    "        study_id_df.loc[t, 'zz'] = zz\n",
    "\n",
    "    # 返回更新后的DataFrame\n",
    "    return study_id_df\n",
    "\n",
    "#read all mri for one patient\n",
    "def load_for_one(study_id_df):\n",
    "    # 使用 groupby 对 DataFrame 进行分组，依据是 'series_description' 和 'series_id'\n",
    "    # agg('first') 表示对每个分组应用 'first' 聚合函数，即选取每组的第一行数据\n",
    "    # index 表示返回分组后各个组的唯一标识\n",
    "    gb = study_id_df.groupby(['series_description', 'series_id']).agg('first').index\n",
    "\n",
    "    # 初始化一个列表，用于存储每个序列的 MRI 数据\n",
    "    mri = []\n",
    "\n",
    "    # 遍历分组后得到的索引\n",
    "    for series_description, series_id in gb:\n",
    "        # 对于每个序列，调用 load_and_split_mri_from_dicom_dir 函数\n",
    "        # 这个函数负责从 DICOM 目录加载数据，并将其分割成单独的 MRI 数据\n",
    "        # 将结果添加到 mri 列表中\n",
    "        mri += load_and_split_mri_from_dicom_dir(\n",
    "            study_id=study_id,  # 假设 study_id 是一个全局变量或通过某种方式传入\n",
    "            series_description=series_description,\n",
    "            series_id=series_id\n",
    "        )\n",
    "\n",
    "    # 返回包含所有序列 MRI 数据的列表\n",
    "    return mri\n",
    "\n",
    "\n",
    "#back project 3D to 2d\n",
    "# 这段代码的主要目的是将给定的世界坐标 (xx, yy, zz) 反投影（backproject）到 MRI 体积数据的二维坐标和实例编号上。\n",
    "# 这是通过计算坐标的投影并检查它们是否在图像边界内来完成的。\n",
    "# 如果坐标有效，函数返回 True 和对应的坐标以及实例编号；如果无效，返回 False 和默认值。\n",
    "def backproject_XYZ(xx, yy, zz, mri):\n",
    "    # 从传入的 mri 对象中获取相关信息\n",
    "    r = mri\n",
    "    # 获取分组后的第一行数据，包含序列的元数据\n",
    "    d0 = r.df.iloc[0]\n",
    "\n",
    "    # 提取 ImagePositionPatient 和 ImageOrientationPatient 字段\n",
    "    sx, sy, sz = [float(v) for v in d0.ImagePositionPatient]\n",
    "    o0, o1, o2, o3, o4, o5 = [float(v) for v in d0.ImageOrientationPatient]\n",
    "    # 提取 PixelSpacing 和 SpacingBetweenSlices 字段\n",
    "    delx, dely = d0.PixelSpacing\n",
    "    delz = d0.SpacingBetweenSlices\n",
    "\n",
    "    # 计算方向向量\n",
    "    ax = np.array([o0, o1, o2])\n",
    "    ay = np.array([o3, o4, o5])\n",
    "    # 计算法向量 az 为 ax 和 ay 的叉乘结果\n",
    "    az = np.cross(ax, ay)\n",
    "\n",
    "    # 计算从世界坐标到图像坐标的向量 p\n",
    "    p = np.array([xx - sx, yy - sy, zz - sz])\n",
    "    # 将向量 p 投影到轴上，得到图像坐标 (x, y, z)\n",
    "    x = np.dot(ax, p) / delx\n",
    "    y = np.dot(ay, p) / dely\n",
    "    z = np.dot(az, p) / delz\n",
    "    # 将坐标四舍五入到最近的整数\n",
    "    x = int(round(x))\n",
    "    y = int(round(y))\n",
    "    z = int(round(z))\n",
    "\n",
    "    # 获取三维体积数据的维度\n",
    "    D, H, W = r.volume.shape\n",
    "    # 检查计算出的坐标是否在图像的边界内\n",
    "    inside = (x >= 0) & (x < W) & (y >= 0) & (y < H) & (z >= 0) & (z < D)\n",
    "    if not inside:\n",
    "        # 如果坐标超出边界，返回 False 和默认值\n",
    "        return False, 0, 0, 0, 0\n",
    "\n",
    "    # 如果坐标在边界内，返回 True 和计算出的坐标及对应的实例编号\n",
    "    n = r.df.instance_number.values[z]\n",
    "    return True, x, y, z, n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load kaggle csv\n",
    "desc_df = pd.read_csv(f'{kaggle_dir}/train_series_descriptions.csv')\n",
    "label_df = pd.read_csv(f'{kaggle_dir}/train_label_coordinates.csv')\n",
    "label_df = label_df.merge(desc_df, on=['study_id', 'series_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_ids = label_df['study_id'].unique()\n",
    "st_ids[:3], len(st_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, si in enumerate(tqdm(st_ids, total=len(st_ids))):\n",
    "    pdf = label_df[label_df['study_id']==si]\n",
    "    study_id_df = label_df[label_df.study_id==study_id]\n",
    "    study_id_df = add_XYZ_to_label_df(study_id_df)\n",
    "    for t,d in study_id_df.iterrows():\n",
    "        print('=================================')\n",
    "        # print(d)\n",
    "        print('*****')\n",
    "        xx, yy, zz = d.xx, d.yy, d.zz\n",
    "\n",
    "        found=0\n",
    "        for r in mri:\n",
    "            d0 = r.df.iloc[0]\n",
    "            if not (\n",
    "                (d0.study_id ==d.study_id) & \n",
    "                (d0.series_id ==d.series_id) &\n",
    "                (d.instance_number in r.df.instance_number)\n",
    "            ): continue\n",
    "            inside,x,y,z,n = backproject_XYZ(xx,yy,zz,r)\n",
    "            found+=1\n",
    "            print('truth:', d.instance_number, d.x, d.y)\n",
    "            print('predict:', n, x, y, f'inside={inside}', f'array index z={z}')\n",
    "        print(f'found={found}')\n",
    "        print('')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
